{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dbed1da",
   "metadata": {},
   "source": [
    "<img src=\"images/econ140R_logo.png\" width=\"200\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff12b62",
   "metadata": {},
   "source": [
    "<h1>ECON 140R Class 04</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27807150",
   "metadata": {},
   "source": [
    "Learning objectives:\n",
    "\n",
    "1.  Get more experience with real data\n",
    "\n",
    "<p>\n",
    "    \n",
    "2. Notice that ordinary least squares regression with `lm()` can test average differences across MULTIPLE subgroups    \n",
    "<p>\n",
    "\n",
    "3. With an outcome variable $y_i$ and group identity indicator variables $D^d_i$, $D^c_i$, and $D^f_i$, for example, then this regression:\n",
    "$$\n",
    "y_i = \\alpha + \\beta^d \\cdot D^d_i + \\beta^c \\cdot D^c_i + \\beta^f \\cdot D^f_i + \\epsilon_i\n",
    "$$\n",
    "provides a very convenient way of testing the average differences in $y$:\n",
    "<ul>\n",
    "    <li> between the control group and group $d$: $\\beta^d$\n",
    "    <li> between the control group and group $c$: $\\beta^c$\n",
    "    <li> between the control group and group $f$: $\\beta^f$\n",
    "</ul>\n",
    "\n",
    "<p>\n",
    "   \n",
    "4. In <i>Mastering Metrics</i> Table 1.4, Angrist and Pischke use multivariate OLS to model 5 measures of health care use and 4 health outcomes (9 separate $y$ variables) on three indicator variables $D$ that measure assignment to treatment arms in the RAND Health Insurance Experiment, all of which have more generous insurance than the control group (\"catastrophic plan\")\n",
    "    \n",
    "<p>\n",
    "\n",
    "5. The results in Table 1.4 show that the <i> causal effect</i> of health insurance on health care use appears to be positive and statistically significant, but the causal effect of health insurance on health outcomes appears to be statistically insignificant\n",
    "\n",
    "<p>\n",
    "    \n",
    "6. A \"fine print\" detail is that Angrist and Pischke are doing what's called <i>clustering standard errors at the family level</i>. This last point will definitely not be on any exams."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e531711f-d826-4fce-80ac-9ccce141318f",
   "metadata": {},
   "source": [
    "Data from the 1974-1982 RAND Health Insurance Experiment (HIE) were unearthed by Aviva Aron-Dine, Liran Einav, and Amy Finkelstein (J. Econ. Perspect., 2013). Josh Angrist and J&#246;rn-Steffen Pischke provide an extract online at [Mastering Metrics](https://www.masteringmetrics.com/resources/).\n",
    "\n",
    "Let's examine the data behind Panel A in Table 1.4, which reveals average levels of health care utilization across 5 types of care (the rows) for the \"control group,\" people with catastrophic health insurance only (the leftmost column). In subsequent columns, the authors show us the average difference in the utilization measure in that row between one of the three \"treatment arms\" they argue are useful to consider (deductible, coinsurance, free), and the control group.\n",
    "\n",
    "Here's a clean PNG of Table 1.4:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75212122",
   "metadata": {},
   "source": [
    "<img src=\"MMtbl14.png\" width=\"800\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb625c",
   "metadata": {},
   "source": [
    "Let's load up <b>haven</b> and <b>tidyverse</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fd4880",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(haven)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fec32e0",
   "metadata": {},
   "source": [
    "I have prepared an extract of the RAND HIE data underneath Table 1.4 Panel A in <i>Mastering Metrics</i>. These data include health care utilization outcomes across the four groups that Angrist and Pischke argue are usefully distinguishable, ordered here from least generous to most generous:\n",
    "\n",
    "* Catastrophic plan\n",
    "* Deductible plan\n",
    "* Coinsurance plan\n",
    "* Free plan\n",
    "\n",
    "We have the five utilization measures shown in Table 1.4A here: `ftf` is face-to-face visits; `out_inf` are outpatient expenses; `totadm` is total hospital admissions; `inpdol_inf` are inpatient expenses, and `tot_inf` are total expenses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e742a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_4a <- read_dta(\"data/table1_4.dta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adcdb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head(table1_4a, n = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8caffd",
   "metadata": {},
   "source": [
    "Let's create new data frames for each of the four groups using `filter()`. The shortened group names are:\n",
    "\n",
    "* `plan_catas` = Catastrophic plan \n",
    "* `plan_deduc` = Deductible plan   \n",
    "* `plan_coins` = Coinsurance plan  \n",
    "* `plan_free`  = Free plan   \n",
    "\n",
    "Copy and paste this code below and run it:\n",
    "\n",
    "`table1_4a_catas <- filter(table1_4a, plan_catas == 1)`\n",
    "\n",
    "`table1_4a_deduc <- filter(table1_4a, plan_deduc == 1)`\n",
    "\n",
    "`table1_4a_coins <- filter(table1_4a, plan_coins == 1)`\n",
    "\n",
    "`table1_4a_free  <- filter(table1_4a, plan_free  == 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abe077f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table1_4a_catas <- filter(table1_4a, plan_catas == 1)\n",
    "\n",
    "table1_4a_deduc <- filter(table1_4a, plan_deduc == 1)\n",
    "\n",
    "table1_4a_coins <- filter(table1_4a, plan_coins == 1)\n",
    "\n",
    "table1_4a_free  <- filter(table1_4a, plan_free  == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fc917",
   "metadata": {},
   "source": [
    "What we now have are 4 separate data frames for the 4 groups assigned to different insurance plans.\n",
    "\n",
    "In STAT 20, you might have used `t.test()` to run a comparison between two groups. Let's run `t.test()` on the face-to-face visits `ftf` in the deductible group versus the catastrophic group. This should get us something like the two numbers in the table at upper left.\n",
    "\n",
    "`t.test(table1_4a_deduc$ftf, table1_4a_catas$ftf)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8076a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.test(table1_4a_deduc$ftf, table1_4a_catas$ftf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f38c30",
   "metadata": {},
   "source": [
    "Not exactly clear, is it? The $t$-statistic is 1.53, which in words means that this difference is about 1.5 times its standard error. That's not big enough for us to reject the null hypothesis that the true difference is zero. \n",
    "\n",
    "There's probably an option to `t.test()` that will show us this, but we can also just type it into __R__. Here is the difference between those last two numbers in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6479f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.976766 - 2.784103"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdee9a24",
   "metadata": {},
   "source": [
    "This is indeed the point estimate (0.19) of the average difference that appears at the upper left of Table 1.4A.\n",
    "\n",
    "And then this, the difference divided by the $t$-stat, has to be the estimated standard error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6fa89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "(2.976766 - 2.784103)/1.5318"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cd8271",
   "metadata": {},
   "source": [
    "Unfortunately this is not the standard error (.25) that appears under the .19 at the upper left of Table 1.4A. What's going on? Stay tuned. Let's load in a new library, which will let us run a special version of `lm()` that will help reveal what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522e9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "library(estimatr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236116d1",
   "metadata": {},
   "source": [
    "First, let's run `lm_robust()` with options set to the baseline. The syntax is the same as it is for `lm()`, and we should recover the same results, as long as we set the standard errors to \"classical\" type.\n",
    "\n",
    "`reg_toprow <- lm(ftf ~ plan_deduc + plan_coins + plan_free, data = table1_4a)`\n",
    "\n",
    "`summary(reg_toprow)`\n",
    "\n",
    "`reg_toprowrob <- lm_robust(ftf ~ plan_deduc + plan_coins + plan_free, \n",
    "                           data = table1_4a, se_type = \"classical\")`\n",
    "\n",
    "`summary(reg_toprowrob)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f3cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_toprow <- lm(ftf ~ plan_deduc, data = table1_4a)\n",
    "\n",
    "summary(reg_toprow)\n",
    "\n",
    "reg_toprowrob <- lm_robust(ftf ~ plan_deduc + plan_coins + plan_free,                             data = table1_4a, se_type = \"classical\")\n",
    "\n",
    "summary(reg_toprowrob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e294df08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08ccf82e",
   "metadata": {},
   "source": [
    "Now let's explore what <i>clustering our standard errors at the family level</i> does to our estimates of the standard errors. Because there are families in these data, indexed by the `famid` variable, we might expect that the $\\epsilon$'s that shock a person one way or another within a family might shock the rest of the family as well. Imagine a family car that breaks down, so nobody keeps their checkup appointments.\n",
    "\n",
    "`reg_toprowcluster <- lm_robust(ftf ~ plan_deduc + plan_coins + plan_free, \n",
    "                                data = table1_4a, clusters = famid)`\n",
    "                              \n",
    "`summary(reg_toprowcluster)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4078f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_toprowcluster <- lm_robust(ftf ~ plan_deduc + plan_coins + plan_free, \n",
    "                               data = table1_4a, clusters = famid)\n",
    "\n",
    "summary(reg_toprowcluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24696d15",
   "metadata": {},
   "source": [
    "Compare these results to the top row in Table 1.4A. What do you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353179f2",
   "metadata": {},
   "source": [
    "<font color=\"red\">\n",
    "    This is exactly what we see in the top row of Table 1.4A, with the exception of the bracketed standard deviation [5.50] below the far left-hand side number, 2.78, which is the intercept term here. The SD we could probably get from `summary()` by conditioning on just the control group (`plan_catas`). The rest of the numbers in the row are the estimates shown here and their standard errors.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcf6ba",
   "metadata": {},
   "source": [
    "Compare these results to the results without clustering standard errors at the family level. Which ones are larger?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ec932f",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\">These standard errors, obtained when clustering errors at the family level, are larger than what we saw when we didn't cluster. This is all you need to be able to do for ECON 140: answer a question like this about something that you're observing.\n",
    "It's also OK to speculate a little, too. Clustering like this is similar to but of course not exactly the same as reducing sample size. Here it raises the standard errors, like a reduced sample size would have also.\n",
    "    </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ab6640",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right\"> <span style=\"font-family:Papyrus; \">And they lived happily ever after. The End.</span></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
